{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cabocha.analyzer import CaboChaAnalyzer\n",
    "import pprint\n",
    "text_path = 'data/chap4/neko.txt'\n",
    "cabocha_path = 'data/chap5/neko.txt.cabocha'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cabocha -f1 < $text_path > $cabocha_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 40. 係り受け解析結果の読み込み（形態素）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Morph:\n",
    "    def __init__(self, surface, base, pos, pos1):\n",
    "        self.surface = surface\n",
    "        self.base = base\n",
    "        self.pos = pos\n",
    "        self.pos1 = pos1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseCabocha(block):\n",
    "    lst = []\n",
    "    for line in block.split('\\n'):\n",
    "        if line == '':\n",
    "            return lst\n",
    "        elif line[0] == '*':\n",
    "            continue\n",
    "        (surface, attr) = line.split('\\t')\n",
    "        attr = attr.split(',')\n",
    "        lst.append(Morph(surface, attr[6], attr[0], attr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'surface': '名前', 'base': '名前', 'pos': '名詞', 'pos1': '一般'}\n",
      "{'surface': 'は', 'base': 'は', 'pos': '助詞', 'pos1': '係助詞'}\n",
      "{'surface': 'まだ', 'base': 'まだ', 'pos': '副詞', 'pos1': '助詞類接続'}\n",
      "{'surface': '無い', 'base': '無い', 'pos': '形容詞', 'pos1': '自立'}\n",
      "{'surface': '。', 'base': '。', 'pos': '記号', 'pos1': '句点'}\n"
     ]
    }
   ],
   "source": [
    "with open(cabocha_path, mode='rt', encoding='utf-8') as f:\n",
    "    blockList = f.read().split('EOS\\n')\n",
    "blockList = list(filter(lambda x: x != '', blockList))\n",
    "blockList = [parseCabocha(block) for block in blockList]\n",
    "for m in blockList[2]:\n",
    "    print(vars(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 41. 係り受け解析結果の読み込み（文節・係り受け）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chunk:\n",
    "    def __init__(self, morphs, dst):\n",
    "        self.morphs = morphs\n",
    "        self.dst = dst\n",
    "        self.srcs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseCabocha(block):\n",
    "    def checkCreateChunk(tmp):\n",
    "        if len(tmp) > 0:\n",
    "            c = Chunk(tmp, dst)\n",
    "            lst.append(c)\n",
    "            tmp = []\n",
    "        return tmp\n",
    "    \n",
    "    \n",
    "    lst = []\n",
    "    tmp = []\n",
    "    dst = None\n",
    "    for line in block.split('\\n'):\n",
    "        if line == '':\n",
    "            tmp = checkCreateChunk(tmp)\n",
    "        elif line[0] == '*':\n",
    "            tmp = checkCreateChunk(tmp)\n",
    "            dst = line.split(' ')[2].rstrip('D')\n",
    "        else:\n",
    "            (surface, attr) = line.split('\\t')\n",
    "            attr = attr.split(',')\n",
    "            tmp.append(Morph(surface, attr[6], attr[0], attr[1]))\n",
    "    for i, v in enumerate(lst):\n",
    "        # 係り先なし\n",
    "        if int(v.dst) == -1:\n",
    "            continue\n",
    "        lst[int(v.dst)].srcs.append(i)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['この'] 1 []\n",
      "['書生', 'という', 'の', 'は'] 7 [0]\n",
      "['時々'] 4 []\n",
      "['我々', 'を'] 4 []\n",
      "['捕え', 'て'] 5 [2, 3]\n",
      "['煮', 'て'] 6 [4]\n",
      "['食う', 'という'] 7 [5]\n",
      "['話', 'で', 'ある', '。'] -1 [1, 6]\n"
     ]
    }
   ],
   "source": [
    "with open(cabocha_path, mode='rt', encoding='utf-8') as f:\n",
    "    blockList = f.read().split('EOS\\n')\n",
    "blockList = list(filter(lambda x: x != '', blockList))\n",
    "blockList = [parseCabocha(block) for block in blockList]\n",
    "for m in blockList[7]:\n",
    "    print([mo.surface for mo in m.morphs], m.dst, m.srcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 42. 係り元と係り先の文節の表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sentence(block):\n",
    "    s = ''\n",
    "    for m in block:\n",
    "        for mo in m.morphs:\n",
    "            s += mo.surface\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一\n",
      "　吾輩は猫である。\n",
      "\t猫である\n",
      "吾輩は\t猫である\n",
      "名前はまだ無い。\n",
      "名前は\t無い\n",
      "まだ\t無い\n",
      "　どこで生れたかとんと見当がつかぬ。\n",
      "どこで\t生れたか\n",
      "生れたか\tつかぬ\n",
      "とんと\tつかぬ\n",
      "見当が\tつかぬ\n",
      "何でも薄暗いじめじめした所でニャーニャー泣いていた事だけは記憶している。\n",
      "何でも\t薄暗い\n",
      "薄暗い\t所で\n",
      "じめじめした\t所で\n",
      "所で\t泣いて\n",
      "ニャーニャー\t泣いて\n",
      "泣いて\t記憶している\n",
      "いた事だけは\t記憶している\n",
      "吾輩はここで始めて人間というものを見た。\n",
      "吾輩は\t見た\n",
      "ここで\t始めて\n",
      "始めて\t人間という\n",
      "人間という\tものを\n",
      "ものを\t見た\n",
      "しかもあとで聞くとそれは書生という人間中で一番獰悪な種族であったそうだ。\n",
      "しかも\t種族であったそうだ\n",
      "あとで\t聞くと\n",
      "聞くと\t種族であったそうだ\n",
      "それは\t種族であったそうだ\n",
      "書生という\t人間中で\n",
      "人間中で\t種族であったそうだ\n",
      "一番\t獰悪な\n",
      "獰悪な\t種族であったそうだ\n",
      "この書生というのは時々我々を捕えて煮て食うという話である。\n",
      "この\t書生というのは\n",
      "書生というのは\t話である\n",
      "時々\t捕えて\n",
      "我々を\t捕えて\n",
      "捕えて\t煮て\n",
      "煮て\t食うという\n",
      "食うという\t話である\n",
      "しかしその当時は何という考もなかったから別段恐しいとも思わなかった。\n",
      "しかし\t思わなかった\n",
      "その\t当時は\n",
      "当時は\tなかったから\n",
      "何という\t考も\n",
      "考も\tなかったから\n",
      "なかったから\t思わなかった\n",
      "別段\t恐し\n",
      "恐し\t思わなかった\n",
      "いとも\t思わなかった\n",
      "ただ彼の掌に載せられてスーと持ち上げられた時何だかフワフワした感じがあったばかりである。\n",
      "ただ\t載せられて\n",
      "彼の\t掌に\n",
      "掌に\t載せられて\n",
      "載せられて\t持ち上げられた\n",
      "スーと\t持ち上げられた\n",
      "持ち上げられた\t時\n",
      "時\tフワフワした\n",
      "何だか\tフワフワした\n",
      "フワフワした\t感じが\n",
      "感じが\tあったばかりである\n"
     ]
    }
   ],
   "source": [
    "for block in blockList[:10]:\n",
    "    print_sentence(block)\n",
    "    for m in block:\n",
    "        if int(m.dst) > -1:\n",
    "            s = ''.join([mo.surface for mo in m.morphs if mo.pos != '記号'])\n",
    "            t = ''.join([mo.surface for mo in block[int(m.dst)].morphs if mo.pos != '記号'])\n",
    "            print(f'{s}\\t{t}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 43. 名詞を含む文節が動詞を含む文節に係るものを抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "どこで\t生れたか\n",
      "見当が\tつかぬ\n",
      "所で\t泣いて\n",
      "ニャーニャー\t泣いて\n",
      "いた事だけは\t記憶している\n",
      "吾輩は\t見た\n",
      "ここで\t始めて\n",
      "ものを\t見た\n",
      "あとで\t聞くと\n",
      "我々を\t捕えて\n",
      "掌に\t載せられて\n",
      "スーと\t持ち上げられた\n",
      "時\tフワフワした\n",
      "感じが\tあったばかりである\n"
     ]
    }
   ],
   "source": [
    "for block in blockList[:10]:\n",
    "    for m in block:\n",
    "        if int(m.dst) > -1:\n",
    "            if any([mo.pos == '名詞' for mo in m.morphs]) and any([mo.pos == '動詞' for mo in block[int(m.dst)].morphs]):\n",
    "                s = ''.join([mo.surface for mo in m.morphs if mo.pos != '記号'])\n",
    "                t = ''.join([mo.surface for mo in block[int(m.dst)].morphs if mo.pos != '記号'])\n",
    "                print(f'{s}\\t{t}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 44. 係り受け木の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in /Users/sora/.pyenv/versions/3.8.2/envs/nlp100/lib/python3.8/site-packages (1.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /Users/sora/.pyenv/versions/3.8.2/envs/nlp100/lib/python3.8/site-packages (from pydot) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['この', '書生というのは'], ['書生というのは', '話である'], ['時々', '捕えて'], ['我々を', '捕えて'], ['捕えて', '煮て'], ['煮て', '食うという'], ['食うという', '話である']]\n"
     ]
    }
   ],
   "source": [
    "import pydot\n",
    "\n",
    "block = blockList[7]\n",
    "pairs = []\n",
    "for m in block:\n",
    "    if int(m.dst) > -1:\n",
    "        s = ''.join([mo.surface for mo in m.morphs if mo.pos != '記号'])\n",
    "        t = ''.join([mo.surface for mo in block[int(m.dst)].morphs if mo.pos != '記号'])\n",
    "        pairs.append([s, t])\n",
    "g = pydot.graph_from_edges(pairs)\n",
    "print(pairs)\n",
    "g.write_png('data/chap5/graph.png', prog='dot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 45. 動詞の格パターンの抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_path = 'data/chap5/neko_case.txt'\n",
    "case = []\n",
    "for block in blockList:\n",
    "    for m in block:\n",
    "        post = []\n",
    "        if len(m.srcs) > 0:\n",
    "            # 動詞が含まれる節\n",
    "            if any([mo.pos == '動詞' for mo in m.morphs]):\n",
    "                verb = [mo.base for mo in m.morphs if mo.pos == '動詞']\n",
    "                \n",
    "                for src in m.srcs:\n",
    "                    # 助詞\n",
    "                    post += [mo.base for mo in block[src].morphs if mo.pos == '助詞']\n",
    "                if post :\n",
    "                    post.sort()\n",
    "                    case.append(f\"{verb[0]}\\t{' '.join(post)}\")\n",
    "                \n",
    "with open (case_path, mode='w') as f:\n",
    "    f.write('\\n'.join(case))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 565 云う\tと\n",
      " 442 する\tを\n",
      " 249 思う\tと\n",
      " 199 ある\tが\n",
      " 189 なる\tに\n",
      " 174 する\tに\n",
      " 173 見る\tて\n",
      " 127 する\tと\n",
      " 117 する\tが\n",
      " 105 する\tに を\n",
      "sort: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!sort $case_path | uniq -c | sort -n -r | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 442 する\tを\n",
      " 174 する\tに\n",
      " 127 する\tと\n",
      " 117 する\tが\n",
      " 105 する\tに を\n",
      "  86 する\tて を\n",
      "  59 する\tは\n",
      "  58 する\tて\n",
      "  57 する\tが を\n",
      "  48 する\tから\n"
     ]
    }
   ],
   "source": [
    "!grep \"^する\\t\" $case_path | sort | uniq -c | sort -n -r | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 173 見る\tて\n",
      "  94 見る\tを\n",
      "  21 見る\tて て\n",
      "  20 見る\tから\n",
      "  16 見る\tて を\n",
      "  14 見る\tと\n",
      "  12 見る\tで\n",
      "  11 見る\tから て\n",
      "  11 見る\tは て\n",
      "   8 見る\tに\n"
     ]
    }
   ],
   "source": [
    "!grep \"^見る\\t\" $case_path | sort | uniq -c | sort -n -r | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3 与える\tに を\n",
      "   1 与える\tけれども に は を\n",
      "   1 与える\tじゃあ か と は て を\n",
      "   1 与える\tとして を か\n",
      "   1 与える\tたり て に を\n",
      "   1 与える\tで だけ に を\n",
      "   1 与える\tに は に対して のみ は も\n",
      "   1 与える\tて が は は と て に を\n",
      "   1 与える\tは て に を に\n",
      "   1 与える\tは て に を\n"
     ]
    }
   ],
   "source": [
    "!grep \"^与える\\t\" $case_path | sort | uniq -c | sort -n -r | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 46. 動詞の格フレーム情報の抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['生れる\\tで\\t\\u3000どこで', 'つく\\tか が\\t生れたか 見当が', '泣く\\tで\\t所で', 'する\\tて は\\tいた事だけは 泣いて', '始める\\tで\\tここで', '見る\\tは を\\tものを 吾輩は', '聞く\\tで\\tあとで', '捕える\\tを\\t我々を', '煮る\\tて\\t捕えて', '食う\\tて\\t煮て']\n"
     ]
    }
   ],
   "source": [
    "case = []\n",
    "for block in blockList:\n",
    "    for m in block:\n",
    "        if len(m.srcs) > 0:\n",
    "            if any([mo.pos == '動詞' for mo in m.morphs]):\n",
    "                verb = [mo.base for mo in m.morphs if mo.pos == '動詞']\n",
    "                post = []\n",
    "                post_term = []\n",
    "                for src in m.srcs:\n",
    "                    if any(mo.pos == '助詞' for mo in block[src].morphs):\n",
    "                        # だけはのような場合は「は」\n",
    "                        for mo in block[src].morphs:\n",
    "                            \n",
    "                        post += [mo.base  if mo.pos == '助詞'][-1]\n",
    "                        post_term += [''.join([mo.surface for mo in block[src].morphs])]\n",
    "                if post :\n",
    "                    post.sort()\n",
    "                    post_term.sort()\n",
    "                    case.append(f\"{verb[0]}\\t{' '.join(post)}\\t{' '.join(post_term)}\")\n",
    "print(case[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 47. 機能動詞構文のマイニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# もうちょっと少しきれいにかけそう\n",
    "pre_path = 'data/chap5/neko_pre.txt'\n",
    "predicate = []\n",
    "for block in blockList:\n",
    "    for m in block:\n",
    "        if len(m.srcs) > 0:\n",
    "            # するがある文節\n",
    "            if any([mo.base == 'する' for mo in m.morphs]):\n",
    "                #verb = [mo.base for mo in m.morphs if mo.pos == '動詞']\n",
    "                sahen = ''\n",
    "                for src in m.srcs:\n",
    "                    # サ変接続 + を が \"する\" にかかる\n",
    "                    if any(block[src].morphs[i].pos1 == 'サ変接続' and block[src].morphs[i+1].base == 'を' for i in range(len(block[src].morphs) -1)):\n",
    "                        sahen = ''.join([mo.surface for mo in block[src].morphs])\n",
    "                if sahen :\n",
    "                    post = []\n",
    "                    post_term = []\n",
    "                    # を　を含まない助詞\n",
    "                    for src in m.srcs:\n",
    "                        if any(mo.pos == '助詞' for mo in block[src].morphs):\n",
    "                            post += [mo.base for mo in block[src].morphs if mo.pos == '助詞' and mo.base != 'を']\n",
    "                            post_term += [''.join([mo.surface for mo in block[src].morphs if mo.pos != '記号'])]\n",
    "                    if post:\n",
    "                        post_term = list(filter(lambda x: sahen != x, post_term))\n",
    "                        post.sort()\n",
    "                        post_term.sort()\n",
    "                           \n",
    "                        predicate.append(f\"{sahen + 'する'}\\t{' '.join(post)}\\t{' '.join(post_term)}\")\n",
    "                        \n",
    "with open (pre_path, mode='w') as f:\n",
    "    f.write('\\n'.join(predicate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  25 返事をする\n",
      "  19 挨拶をする\n",
      "  11 話をする\n",
      "   8 質問をする\n",
      "   7 喧嘩をする\n",
      "   6 真似をする\n",
      "   5 相談をする\n",
      "   5 昼寝をする\n",
      "   4 御辞儀をする\n",
      "   4 演説をする\n"
     ]
    }
   ],
   "source": [
    "!cut -f 1  $pre_path | sort | uniq -c | sort -n -r | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 48. 名詞から根へのパスの抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "吾輩は -> 猫である\n",
      "名前は -> 無い\n",
      "どこで -> 生れたか -> つかぬ\n",
      "見当が -> つかぬ\n",
      "何でも -> 薄暗い -> 所で -> 泣いて -> 記憶している\n",
      "所で -> 泣いて -> 記憶している\n",
      "ニャーニャー -> 泣いて -> 記憶している\n",
      "いた事だけは -> 記憶している\n",
      "吾輩は -> 見た\n",
      "ここで -> 始めて -> 人間という -> ものを -> 見た\n",
      "人間という -> ものを -> 見た\n",
      "ものを -> 見た\n",
      "あとで -> 聞くと -> 種族であったそうだ\n",
      "それは -> 種族であったそうだ\n",
      "書生という -> 人間中で -> 種族であったそうだ\n",
      "人間中で -> 種族であったそうだ\n",
      "一番 -> 獰悪な -> 種族であったそうだ\n",
      "獰悪な -> 種族であったそうだ\n",
      "書生というのは -> 話である\n",
      "我々を -> 捕えて -> 煮て -> 食うという -> 話である\n",
      "当時は -> なかったから -> 思わなかった\n",
      "何という -> 考も -> なかったから -> 思わなかった\n",
      "考も -> なかったから -> 思わなかった\n",
      "彼の -> 掌に -> 載せられて -> 持ち上げられた -> 時 -> フワフワした -> 感じが -> あったばかりである\n",
      "掌に -> 載せられて -> 持ち上げられた -> 時 -> フワフワした -> 感じが -> あったばかりである\n",
      "スーと -> 持ち上げられた -> 時 -> フワフワした -> 感じが -> あったばかりである\n",
      "時 -> フワフワした -> 感じが -> あったばかりである\n",
      "感じが -> あったばかりである\n"
     ]
    }
   ],
   "source": [
    "for block in blockList[:10]:\n",
    "    for m in block:\n",
    "        dst = int(m.dst)\n",
    "        if dst > -1:\n",
    "            if any([mo.pos == '名詞' for mo in m.morphs]):\n",
    "                start = ''.join([mo.surface for mo in m.morphs if mo.pos != '記号'])\n",
    "                \n",
    "                node = []\n",
    "                while dst != -1:\n",
    "                    node += [''.join([mo.surface for mo in block[dst].morphs if mo.pos != '記号'])]\n",
    "                    dst = int(block[dst].dst)\n",
    "                if node :\n",
    "                    print(f\"{start} -> {' -> '.join(node)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 49. 名詞間の係り受けパスの抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一\n",
      "[]\n",
      "　吾輩は猫である。\n",
      "[('吾輩は', '猫である')]\n",
      "名前はまだ無い。\n",
      "[]\n",
      "　どこで生れたかとんと見当がつかぬ。\n",
      "[('どこで', '見当が')]\n",
      "何でも薄暗いじめじめした所でニャーニャー泣いていた事だけは記憶している。\n",
      "[('何でも', '所で'), ('何でも', 'ニャーニャー'), ('何でも', 'いた事だけは'), ('何でも', '記憶している'), ('所で', 'ニャーニャー'), ('所で', 'いた事だけは'), ('所で', '記憶している'), ('ニャーニャー', 'いた事だけは'), ('ニャーニャー', '記憶している'), ('いた事だけは', '記憶している')]\n",
      "吾輩はここで始めて人間というものを見た。\n",
      "[('吾輩は', 'ここで'), ('吾輩は', '人間という'), ('吾輩は', 'ものを'), ('ここで', '人間という'), ('ここで', 'ものを'), ('人間という', 'ものを')]\n",
      "しかもあとで聞くとそれは書生という人間中で一番獰悪な種族であったそうだ。\n",
      "[('あとで', 'それは'), ('あとで', '書生という'), ('あとで', '人間中で'), ('あとで', '一番'), ('あとで', '獰悪な'), ('あとで', '種族であったそうだ'), ('それは', '書生という'), ('それは', '人間中で'), ('それは', '一番'), ('それは', '獰悪な'), ('それは', '種族であったそうだ'), ('書生という', '人間中で'), ('書生という', '一番'), ('書生という', '獰悪な'), ('書生という', '種族であったそうだ'), ('人間中で', '一番'), ('人間中で', '獰悪な'), ('人間中で', '種族であったそうだ'), ('一番', '獰悪な'), ('一番', '種族であったそうだ'), ('獰悪な', '種族であったそうだ')]\n",
      "この書生というのは時々我々を捕えて煮て食うという話である。\n",
      "[('書生というのは', '我々を'), ('書生というのは', '話である'), ('我々を', '話である')]\n",
      "しかしその当時は何という考もなかったから別段恐しいとも思わなかった。\n",
      "[('当時は', '何という'), ('当時は', '考も'), ('何という', '考も')]\n",
      "ただ彼の掌に載せられてスーと持ち上げられた時何だかフワフワした感じがあったばかりである。\n",
      "[('彼の', '掌に'), ('彼の', 'スーと'), ('彼の', '時'), ('彼の', '感じが'), ('掌に', 'スーと'), ('掌に', '時'), ('掌に', '感じが'), ('スーと', '時'), ('スーと', '感じが'), ('時', '感じが')]\n"
     ]
    }
   ],
   "source": [
    "# わからん\n",
    "for block in blockList[:10]:\n",
    "    print_sentence(block)\n",
    "    norn_pair = []\n",
    "    for i, m in enumerate(block):\n",
    "        # 名詞があった時\n",
    "        nornX = ''\n",
    "        if any([mo.pos == '名詞' for mo in m.morphs]):\n",
    "            nornX = ''.join([mo.surface for mo in m.morphs if mo.pos != '記号'])\n",
    "            for i2, m2 in enumerate(block[i+1:]):\n",
    "                nornY = ''\n",
    "                if any([mo2.pos == '名詞' for mo2 in m2.morphs]):\n",
    "                    nornY = ''.join([mo2.surface for mo2 in m2.morphs if mo2.pos != '記号'])\n",
    "                if nornY:\n",
    "                    norn_pair.append((nornX, nornY))\n",
    "    \n",
    "    # 名詞句pair\n",
    "        \n",
    "            \n",
    "#         # 名詞が文中にある\n",
    "#         for i, mo in enumerate(m.morphs):\n",
    "#             if mo.pos == '名詞':\n",
    "#                 for i2, mo2 in enumerate(m.morphs[i+1:]):\n",
    "#                     print(mo2.surface)\n",
    "#                     if mo2.pos == '名詞':\n",
    "#                         print(mo2.surface)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
