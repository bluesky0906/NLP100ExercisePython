{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "path = \"data/chap6/newsCorpora.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50. データの入手・整形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "df = pd.read_csv(path, sep='\\t', header=None)\n",
    "df.columns = ['ID', 'TITLE', 'URL', 'PUBLISHER', 'CATEGORY', 'STORY', 'HOSTNAME', 'TIMESTAMP']\n",
    "publishers = ['Reuters', 'Huffington Post', 'Businessweek', 'Contactmusic.com', 'Daily Mail']\n",
    "selected_df = df[df['PUBLISHER'].isin(publishers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "selected_df = selected_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "train_df, valid_test_df = train_test_split(selected_df, train_size=0.8)\n",
    "valid_df, test_df = train_test_split(valid_test_df, train_size=0.5)\n",
    "columns = ['CATEGORY','TITLE']\n",
    "train_df.to_csv(\"data/chap6/train.txt\", columns=columns, sep='\\t', header=False, index=False)\n",
    "test_df.to_csv(\"data/chap6/test.txt\", columns=columns, sep='\\t', header=False, index=False)\n",
    "valid_df.to_csv(\"data/chap6/valid.txt\", columns=columns, sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b    5627\n",
       "e    5279\n",
       "t    1524\n",
       "m     910\n",
       "Name: CATEGORY, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_df['CATEGORY'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 51. 特徴量抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_count = CountVectorizer()\n",
    "x_train = vec_count.fit_transform(train_df['TITLE'])\n",
    "x_test = vec_count.transform(test_df['TITLE'])\n",
    "x_valid = vec_count.transform(valid_df['TITLE'])\n",
    "\n",
    "np.savetxt('data/chap6/train.feature.txt', x_train.toarray(), fmt='%d') # スパース行列から密行列に変換\n",
    "np.savetxt('data/chap6/valid.feature.txt', x_valid.toarray(), fmt='%d')\n",
    "np.savetxt('data/chap6/test.feature.txt', x_test.toarray(), fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 52. 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sora/.pyenv/versions/3.8.2/envs/nlp100/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(x_train, train_df['CATEGORY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 53. 予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teenage Mutant Ninja Turtles: How Not To Market A Movie\n",
      "business: 0.12069455687130613\n",
      "entertainment: 0.854277946925457\n",
      "health: 0.007477001523512991\n",
      "science and technology: 0.01755049467972399\n"
     ]
    }
   ],
   "source": [
    "dic = {'b':'business', 't':'science and technology', 'e' : 'entertainment', 'm' : 'health'}\n",
    "def predict(text):\n",
    "    text = [text]\n",
    "    x = vec_count.transform(text)\n",
    "    ls_proba = clf.predict_proba(x)\n",
    "    for proba in ls_proba:\n",
    "        for c, p in zip(clf.classes_, proba):\n",
    "            print (dic[c]+':',p)\n",
    "s = train_df.iloc[0]['TITLE']\n",
    "print(s)\n",
    "predict(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 54. 正解率の計測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9962518740629686\n",
      "0.9047976011994003\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = clf.predict(x_train)\n",
    "y_test_pred = clf.predict(x_test)\n",
    "y_train = train_df['CATEGORY']\n",
    "y_test = test_df['CATEGORY']\n",
    "print (accuracy_score(y_train, y_train_pred))\n",
    "print (accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 55. 混同行列の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      b     t     e    m\n",
      "b  4472     6     1    0\n",
      "t    14  1225     3    0\n",
      "e     8     2  4220    0\n",
      "m     4     0     2  715\n",
      "     b    t    e   m\n",
      "b  530   16   16   3\n",
      "t   26  109   13   1\n",
      "e    9    3  510   3\n",
      "m   14    8   15  58\n"
     ]
    }
   ],
   "source": [
    "labels = ['b','t','e','m']\n",
    "train_cm = confusion_matrix(y_train, y_train_pred, labels=labels)\n",
    "test_cm = confusion_matrix(y_test, y_test_pred, labels=labels)\n",
    "train_cm_labeled = pd.DataFrame(train_cm, columns=labels, index=labels)\n",
    "test_cm_labeled = pd.DataFrame(test_cm, columns=labels, index=labels)\n",
    "print(train_cm_labeled)\n",
    "print(test_cm_labeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 56. 適合率，再現率，F1スコアの計測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   precision score  recall score  f1 score\n",
      "b         0.915371      0.938053  0.926573\n",
      "t         0.801471      0.731544  0.764912\n",
      "e         0.920578      0.971429  0.945320\n",
      "m         0.892308      0.610526  0.725000\n"
     ]
    }
   ],
   "source": [
    "ps = precision_score(y_test, y_test_pred, average=None, labels=labels)\n",
    "rs = recall_score(y_test, y_test_pred, average=None, labels=labels)\n",
    "f1 = f1_score(y_test, y_test_pred, average=None, labels=labels)\n",
    "\n",
    "df = pd.DataFrame(data={'precision score': ps, 'recall score': rs, 'f1 score': f1}, index = labels)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   precision score  recall score  f1 score\n",
      "b         0.904798      0.904798  0.904798\n",
      "t         0.904798      0.904798  0.904798\n",
      "e         0.904798      0.904798  0.904798\n",
      "m         0.904798      0.904798  0.904798\n"
     ]
    }
   ],
   "source": [
    "micro_ps = precision_score(y_test, y_test_pred, average='micro', labels=labels)\n",
    "micro_rs = recall_score(y_test, y_test_pred, average='micro', labels=labels)\n",
    "micro_f1 = f1_score(y_test, y_test_pred, average='micro', labels=labels)\n",
    "\n",
    "micro_df = pd.DataFrame(data={'precision score': micro_ps, 'recall score': micro_rs, 'f1 score': micro_f1}, index = labels)\n",
    "print(micro_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   precision score  recall score  f1 score\n",
      "b         0.882432      0.812888  0.840451\n",
      "t         0.882432      0.812888  0.840451\n",
      "e         0.882432      0.812888  0.840451\n",
      "m         0.882432      0.812888  0.840451\n"
     ]
    }
   ],
   "source": [
    "macro_ps = precision_score(y_test, y_test_pred, average='macro', labels=labels)\n",
    "macro_rs = recall_score(y_test, y_test_pred, average='macro', labels=labels)\n",
    "macro_f1 = f1_score(y_test, y_test_pred, average='macro', labels=labels)\n",
    "\n",
    "macro_df = pd.DataFrame(data={'precision score': macro_ps, 'recall score': macro_rs, 'f1 score': macro_f1}, index = labels)\n",
    "print(macro_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 57. 特徴量の重みの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.17613076  0.0200178   0.00428534 ... -0.00044779 -0.05595252\n",
      " -0.00114271]\n",
      "business\n",
      "['bank' 'fed' 'ecb' 'china' 'yellen' 'obamacare' 'ukraine' 'dollar' 'euro'\n",
      " 'oil']\n",
      "['activision' 'aereo' 'ebola' 'twitch' 'cap' 'she' 'heartbleed'\n",
      " 'subscription' 'nintendo' 'virus']\n",
      "[-0.10577076 -0.01482196 -0.00225462 ...  0.00464226  0.11809141\n",
      "  0.00391573]\n",
      "entertainment\n",
      "['chris' 'paul' 'kardashian' 'thrones' 'miley' 'transformers' 'film'\n",
      " 'movie' 'cyrus' 'beyonce']\n",
      "['google' 'facebook' 'gm' 'china' 'billion' 'risk' 'ebola' 'microsoft'\n",
      " 'study' 'climate']\n",
      "[-0.03916612 -0.00257808 -0.00096667 ... -0.00184498 -0.02072804\n",
      " -0.00081899]\n",
      "health\n",
      "['ebola' 'fda' 'cancer' 'drug' 'study' 'mers' 'cases' 'cdc' 'doctors'\n",
      " 'alzheimer']\n",
      "['gm' 'dimon' 'facebook' 'climate' 'apple' 'twitter' 'google' 'bank'\n",
      " 'sales' 'play']\n",
      "[-0.03119388 -0.00261776 -0.00106405 ... -0.00234949 -0.04141085\n",
      " -0.00195403]\n",
      "science and technology\n",
      "['google' 'facebook' 'microsoft' 'climate' 'apple' 'activision' 'tesla'\n",
      " 'heartbleed' 'nasa' 'fcc']\n",
      "['stocks' 'percent' 'move' 'thrones' 'valued' 'american' 'fed' 'accused'\n",
      " 'movie' 'drug']\n"
     ]
    }
   ],
   "source": [
    "names = np.array(vec_count.get_feature_names())\n",
    "labels=['b','t','e','m']\n",
    "for c, coef in zip(clf.classes_, clf.coef_): # カテゴリ毎に表示する\n",
    "    idx = np.argsort(coef)[::-1] # 降順ソート\n",
    "    print (dic[c])\n",
    "    print (names[idx][:10]) # 重みの高い特徴量トップ10\n",
    "    print (names[idx][-10:][::-1]) # 重みの低い特徴量トップ10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 58. 正則化パラメータの変更"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
